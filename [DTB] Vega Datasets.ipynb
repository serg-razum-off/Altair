{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pandas.plot() base training notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">>> Imports done\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "from tqdm import tqdm\n",
    "import gc\n",
    "\n",
    "print(\">>> Imports done\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading and examining available Vega datasets "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==================== CSV datasets in processing ====================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 22/22 [00:12<00:00,  1.82it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "==================== JSON datasets in processing ====================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 45/45 [00:37<00:00,  1.20it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "==================== Datasets, that were not loaded: [7] ====================\n",
      "https://raw.githubusercontent.com/vega/vega-datasets/main/data/annual-precip.json\n",
      "https://raw.githubusercontent.com/vega/vega-datasets/main/data/earthquakes.json\n",
      "https://raw.githubusercontent.com/vega/vega-datasets/main/data/londonBoroughs.json\n",
      "https://raw.githubusercontent.com/vega/vega-datasets/main/data/londonTubeLines.json\n",
      "https://raw.githubusercontent.com/vega/vega-datasets/main/data/miserables.json\n",
      "https://raw.githubusercontent.com/vega/vega-datasets/main/data/us-10m.json\n",
      "https://raw.githubusercontent.com/vega/vega-datasets/main/data/world-110m.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# this is ChatGPT generated code; debugging and task clarification was mine =)\n",
    "\n",
    "url = 'https://github.com/vega/vega-datasets/tree/main/data'\n",
    "\n",
    "response = requests.get(url)\n",
    "soup = BeautifulSoup(response.content, 'html.parser')\n",
    "\n",
    "csv_links = [a['href'] for a in soup.find_all('a', href=True) if a['href'].endswith('.csv')]\n",
    "json_links = [a['href'] for a in soup.find_all('a', href=True) if a['href'].endswith('.json')]\n",
    "\n",
    "datasets = []\n",
    "err_datasets = []\n",
    "\n",
    "print(\"=\"*20 + \" CSV datasets in processing \" + \"=\"*20)\n",
    "for link in tqdm(csv_links):\n",
    "    url = 'https://raw.githubusercontent.com' + link.replace('/blob/', '/')\n",
    "    try:\n",
    "        df = pd.read_csv(url)\n",
    "        datasets.append({\n",
    "            'DF_Name': link.split('/')[-1],\n",
    "            'DF_Number_of_Rows': df.shape[0],\n",
    "            'DF_Number_of_Columns': df.shape[1],\n",
    "            'DF': df\n",
    "        })\n",
    "    except:\n",
    "        err_datasets.append(url)\n",
    "\n",
    "print(\"\\n\" + \"=\"*20 + \" JSON datasets in processing \" + \"=\"*20)\n",
    "for link in tqdm(json_links):\n",
    "    url = 'https://raw.githubusercontent.com' + link.replace('/blob/', '/')\n",
    "    try:\n",
    "        df = pd.read_json(url)\n",
    "        datasets.append({\n",
    "            'DF_Name': link.split('/')[-1],\n",
    "            'DF_Number_of_Rows': df.shape[0],\n",
    "            'DF_Number_of_Columns': df.shape[1],\n",
    "            'DF': df\n",
    "        })\n",
    "    except:\n",
    "        err_datasets.append(url)\n",
    "\n",
    "print(\"\\n\" +\"=\"*20 + f\" Datasets, that were not loaded: [{len(err_datasets)}] \" +  \"=\"*20)\n",
    "for ds in err_datasets:\n",
    "    print(ds)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A new issue has been opened for the Vega Team regarding datasets that cannot be loaded:\n",
    "https://github.com/vega/vega-datasets/issues/438"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_datasets = pd.DataFrame(datasets).set_index('DF_Name')\n",
    "\n",
    "del datasets\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_datasets.to_pickle('data/vega_datasets.pkl')\n",
    "# df_datasets = pd.read_pickle('data/vega_datasets.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>DF_Number_of_Rows</th>\n",
       "      <th>DF_Number_of_Columns</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DF_Name</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>flights-3m.csv</th>\n",
       "      <td>231083</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>flights-200k.json</th>\n",
       "      <td>231083</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>zipcodes.csv</th>\n",
       "      <td>42049</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>flights-20k.json</th>\n",
       "      <td>20000</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>flights-10k.json</th>\n",
       "      <td>10000</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>birdstrikes.csv</th>\n",
       "      <td>10000</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>seattle-weather-hourly-normals.csv</th>\n",
       "      <td>8759</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>jobs.json</th>\n",
       "      <td>7650</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>platformer-terrain.json</th>\n",
       "      <td>7514</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>football.json</th>\n",
       "      <td>6508</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                    DF_Number_of_Rows  DF_Number_of_Columns\n",
       "DF_Name                                                                    \n",
       "flights-3m.csv                                 231083                     5\n",
       "flights-200k.json                              231083                     3\n",
       "zipcodes.csv                                    42049                     6\n",
       "flights-20k.json                                20000                     5\n",
       "flights-10k.json                                10000                     5\n",
       "birdstrikes.csv                                 10000                    14\n",
       "seattle-weather-hourly-normals.csv               8759                     4\n",
       "jobs.json                                        7650                     5\n",
       "platformer-terrain.json                          7514                     8\n",
       "football.json                                    6508                     6"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_datasets = df_datasets.drop('DF', axis=1) if 'DF' in df_datasets.columns else df_datasets\n",
    "\n",
    "df_datasets.sort_values('DF_Number_of_Rows', ascending=False)[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "err_datasets = [\n",
    "'https://raw.githubusercontent.com/vega/vega-datasets/main/data/annual-precip.json',\n",
    "'https://raw.githubusercontent.com/vega/vega-datasets/main/data/earthquakes.json',\n",
    "'https://raw.githubusercontent.com/vega/vega-datasets/main/data/londonBoroughs.json',\n",
    "'https://raw.githubusercontent.com/vega/vega-datasets/main/data/londonTubeLines.json',\n",
    "'https://raw.githubusercontent.com/vega/vega-datasets/main/data/miserables.json',\n",
    "'https://raw.githubusercontent.com/vega/vega-datasets/main/data/us-10m.json',\n",
    "'https://raw.githubusercontent.com/vega/vega-datasets/main/data/world-110m.json',\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['ValueError', 'All arrays must be of the same length'],\n",
       " ['ValueError', 'All arrays must be of the same length'],\n",
       " ['ValueError', 'All arrays must be of the same length'],\n",
       " ['ValueError', 'All arrays must be of the same length'],\n",
       " ['ValueError', 'All arrays must be of the same length'],\n",
       " ['ValueError',\n",
       "  'Mixing dicts with non-Series may lead to ambiguous ordering.'],\n",
       " ['ValueError',\n",
       "  'Mixing dicts with non-Series may lead to ambiguous ordering.']]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "errs = []\n",
    "for ds in err_datasets:\n",
    "    try:\n",
    "        pd.read_json(ds)\n",
    "    except Exception as e:\n",
    "        errs.append([type(e).__name__, str(e)])\n",
    "\n",
    "errs"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "altair",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
